#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Utility files and modules"""

import os
import random
import time
from functools import lru_cache, wraps
from io import BytesIO
from itertools import combinations
from pathlib import Path
from typing import Optional, Union

import boto3
import librosa
import numpy as np
import pandas as pd
import requests
import sqlalchemy as sa
import torch
from dotenv import find_dotenv, load_dotenv
from pedalboard.io import AudioFile
from tqdm import tqdm


MODEL_URL = 'https://github.com/bleugreen/deeprhythm/raw/main/'

SEED = 42
DEVICE = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
EPS = 1e-4

SAMPLE_RATE = 22050    # used by default in `deeprhythm`
CLIP_LENGTH = 8

# Setting these values ensures that we get 99.7% of beatstars tracks
MIN_BPM, MAX_BPM = 50, 200
BPM_SCALING = 1.15    # when creating N BPM classes, class N + 1 == N * BPM_SCALING
MIN_DURATION, MAX_DURATION = 60, 360   # between 1 and 6 minutes

# Gracefully load up environment variables whenever this module is imported
denv = find_dotenv()
if denv is not None:
    load_dotenv(denv)

# AWS resources
S3 = boto3.resource("s3")
S3_CLIENT = boto3.client("s3")
S3BucketClass = type(S3.Bucket('dummy'))
S3ObjectClass = type(S3.Object('dummy-bucket', 'dummy-key'))

AUDIO_EXTS = ("wav", "mp3", "flac", "m4a", "mpeg")    # should be comprehensive


def get_weights(filename="deeprhythm_colossal-0.7.pth", quiet=False):
    # Construct the path to save the model weights
    home_dir = os.path.expanduser("~")
    model_dir = os.path.join(home_dir, ".local", "share", "deeprhythm_colossal")
    if not os.path.exists(model_dir):
        os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, filename)

    # Check if the model weights already exist
    if not os.path.isfile(model_path):
        print("Downloading model weights...")
        # Download the model weights
        try:
            r = requests.get(MODEL_URL + filename, allow_redirects=True)
            if r.status_code == 200:
                with open(model_path, 'wb') as f:
                    f.write(r.content)
                print("Model weights downloaded successfully.")
            else:
                print(f"Failed to download model weights. HTTP Error: {r.status_code}")
        except Exception as e:
            print(f"An error occurred during the download: {e}")
    else:
        if not quiet:
            print("Model weights already exist.")

    return model_path


def load_and_split_audio(
        filename: Union[str, Path],
        sr: int = SAMPLE_RATE,
        clip_length: int = CLIP_LENGTH,
        share_mem: bool =False
) -> torch.Tensor:
    """
    Load an audio file, split it into 8-second clips, and return a single tensor of all clips.

    Parameters:
        - filename: Path to the audio file.
        - sr: Sampling rate to use for loading the audio.
        - clip_length: Length of each clip in seconds.

    Returns:
        A tensor of shape [clips, audio] where each row is an 8-second clip.
    """

    clips = []
    clip_samples = sr * clip_length
    try:
        audio, _ = librosa.load(filename, sr=sr)
        for i in range(0, len(audio), clip_samples):
            if i + clip_samples <= len(audio):
                clip_tensor = torch.tensor(audio[i:i + clip_samples], dtype=torch.float32)
                clips.append(clip_tensor)
        if clips:
            stacked_clips = torch.stack(clips, dim=0)
        else:
            return None

        if share_mem:
            stacked_clips.share_memory_()

        return stacked_clips
    except Exception as e:
        print(e, filename)


def split_audio(
        audio,
        sr: int = SAMPLE_RATE,
        clip_length: int = CLIP_LENGTH,
        share_mem=False
) -> torch.Tensor:
    """
    Load an audio file, split it into 8-second clips, and return a single tensor of all clips.

    Parameters:
        - audio: Array generated by librosa.load representing the audio.
        - sr: Sampling rate to used for loading the audio.
        - clip_length: Length of each clip in seconds.

    Returns:
        A tensor of shape [clips, audio] where each row is an 8-second clip.
    """

    clips = []
    clip_samples = sr * clip_length
    try:
        for i in range(0, len(audio), clip_samples):
            if i + clip_samples <= len(audio):
                clip_tensor = torch.tensor(audio[i:i + clip_samples], dtype=torch.float32)
                clips.append(clip_tensor)
        if clips:
            stacked_clips = torch.stack(clips, dim=0)
        else:
            return None

        if share_mem:
            stacked_clips.share_memory_()

        return stacked_clips
    except Exception as e:
        print(e, audio)


def bpm_to_class(bpm, min_bpm: int = MIN_BPM, max_bpm: int = MAX_BPM, num_classes: int = 256) -> int:
    """
    Map a BPM value to a class index.
    """
    # TODO: almost definitely something wrong here
    class_width = (max_bpm - min_bpm) / num_classes
    class_index = int((bpm - min_bpm) // class_width)
    return max(0, min(num_classes - 1, class_index))


def class_to_bpm(class_index, min_bpm: int = MIN_BPM, max_bpm: int = MAX_BPM, num_classes: int = 256) -> int:
    """
    Map a class index back to a BPM value (to the center of the class interval).
    """
    # TODO: almost definitely something wrong here
    class_width = (max_bpm - min_bpm) / num_classes
    bpm = min_bpm + class_width * (class_index)
    return bpm


def lists_are_unique(*list_of_strings: list[str]) -> bool:
    """
    Takes in an arbitrary number of lists of strings and checks that they are all unique
    """
    for sp1, sp2 in combinations(list_of_strings, 2):
        if any(i in sp2 for i in sp1):
            return False
    return True


def timeit(func):
    """
    Wrapper function that times the execution of a function.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        end = time.perf_counter()
        elapsed = end - start
        # If the function returns multiple values in a tuple, keep that tuple but prepend the elapsed time
        if isinstance(result, tuple):
            return *result, elapsed
        else:
            return result, elapsed
    return wrapper


@lru_cache(maxsize=1000)
def get_bucket(bucket_name: str) -> S3BucketClass:
    """
    Get a bucket from a string, with caching to prevent redundant reads
    """
    return S3.Bucket(bucket_name)


# noinspection PyTypeChecker
def get_bpm_classes(min_bpm: int = MIN_BPM, max_bpm: int = MAX_BPM, bpm_scaling: float = BPM_SCALING) -> np.ndarray:
    """
    Creates an array of BPM classes

    Where bpm_classes[0] == min_bpm, and bpm_classes[n] == bpm_classes[n-1] * bpm_scaling
    """
    bpm_classes = [min_bpm]
    while bpm_classes[-1] <= max_bpm:
        bpm_classes.append(bpm_classes[-1] * bpm_scaling)
    return np.array([i_ for i_ in bpm_classes if i_ <= max_bpm])


@lru_cache(maxsize=1000)
def get_object(obj: str, bucket: Union[str, S3BucketClass]) -> S3ObjectClass:
    """
    Grab a S3 object from a bucket
    """
    if isinstance(bucket, str):
        bucket = get_bucket(bucket)
    return S3.Object(key=obj, bucket_name=bucket.name)


@lru_cache(maxsize=None)
def get_db_engine(
        user: Optional[str] = None,
        password: Optional[str] = None,
        hostname: Optional[str] = None
) -> sa.engine.base.Engine:
    """
    Creates database engine in sqlalchemy, can be passed easily to e.g. pandas
    """
    # Use environment variables if not passed
    user_ = user if user is not None else os.environ.get("DB_USERNAME")
    password_ = password if password is not None else os.environ.get("DB_PASSWORD")
    hostname_ = hostname if hostname is not None else os.environ.get("DB_HOSTNAME")
    return sa.create_engine(
        f"postgresql+psycopg2://{user_}:{password_}@{hostname_}/postgres",
        pool_pre_ping=True,
    )


@lru_cache(maxsize=None)
def load_df_from_postgres(query: str) -> pd.DataFrame:
    """
    Loads up a dataframe with a given postgresql query
    """
    engine = get_db_engine()
    return pd.read_sql(query, engine)


def list_files_in_bucket(bucket: Union[str, S3BucketClass]) -> list[str]:
    """
    Returns all files in a bucket as a list of strings
    """
    if isinstance(bucket, str):
        bucket = get_bucket(bucket)
    return [f.key for f in tqdm(bucket.objects.all(), desc="Listing files in bucket...")]


# noinspection PyTypeChecker
def read_s3_object_to_audiofile(
        obj: Union[str, S3ObjectClass],
        bucket: Union[str, S3BucketClass] = None
) -> AudioFile:
    """
    Read a S3 object and convert it to a pedalboard audio file
    """
    if bucket is None:
        bucket = get_bucket("cl-dev-external-beats")
    if isinstance(obj, str):
        obj = get_object(obj, bucket)
    obj_bytes = BytesIO(obj.get()["Body"].read())
    return AudioFile(obj_bytes)


def seed_everything(seed: int = SEED) -> None:
    """
    Set the random seeds for ML libraries.
    """
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # safe to call even if cuda is not available
    random.seed(seed)
    np.random.seed(seed)


def get_project_root() -> Path:
    """
    Returns the root directory of the project.
    """
    # Possibly the root directory, but doesn't always work when running from the CLI for some reason
    poss_path = Path(__file__).parent.parent
    # The root directory should always have these files (this is pretty hacky)
    expected_files = ["tests", "pyproject.toml", "poetry.lock", ".gitignore"]
    if all((poss_path / fp).exists() for fp in expected_files):
        return poss_path
    else:
        return Path.cwd()
